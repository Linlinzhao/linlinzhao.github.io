{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch中的基础操作\n",
    "\n",
    "Pytorch的设计哲学：\n",
    "\n",
    "1. GPU版的Numpy\n",
    "2. 高效灵活的深度学习平台\n",
    "\n",
    "\n",
    "\n",
    "Pytorch has two design philosophies. \n",
    "\n",
    "I. A replacement for Numpy to use the powers of GPU.\n",
    "\n",
    "II. A fast and flexible platform for deep learning research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "numpy中运算，函数，索引的规则和方法可以无缝应用到pytorch的tensor操作。但需要特别注意的一点是，pytorch中in place操作如果有下划线的话，会改变调用该操作的变量。具体参见下面的例子。\n",
    "\n",
    "\n",
    "### 基本函数\n",
    "1. In-place functions are always post-fixed with \"_\" will mutate the object! But if the function is not post-fixed with \"_\", then the object will not be mutated. See the example below. \n",
    "\n",
    "2. Zoo of manipulations for torch can be found [here](http://pytorch.org/docs/master/torch.html)\n",
    "\n",
    "If a variable \"x\" is defined by being assigned with another variable \"y\", the in-place operation which changes \"x\" will also change \"y\". From this, we should be careful with combination of assignment and in_place operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.8031  0.0763  0.4798\n",
      " 0.6118  0.6341  0.4783\n",
      " 0.0423  0.9399  0.1805\n",
      " 0.0696  0.5616  0.8898\n",
      "[torch.FloatTensor of size 4x3]\n",
      "\n",
      "\n",
      " 0.8031  0.6118  0.0423  0.0696\n",
      " 0.0763  0.6341  0.9399  0.5616\n",
      " 0.4798  0.4783  0.1805  0.8898\n",
      "[torch.FloatTensor of size 3x4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(4, 3) #randomly generated tensors\n",
    "print x\n",
    "x.t_() #transpose of x, note that x has been changed!\n",
    "print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.8031  0.0763  0.4798\n",
      " 0.6118  0.6341  0.4783\n",
      " 0.0423  0.9399  0.1805\n",
      " 0.0696  0.5616  0.8898\n",
      "[torch.FloatTensor of size 4x3]\n",
      "\n",
      "\n",
      " 0.8031  0.6118  0.0423  0.0696\n",
      " 0.0763  0.6341  0.9399  0.5616\n",
      " 0.4798  0.4783  0.1805  0.8898\n",
      "[torch.FloatTensor of size 3x4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print x.t()\n",
    "print x #the x is still the previous modified, which is not mutated by x.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.8031  0.6118  0.0423  0.0696\n",
      " 0.0763  0.6341  0.9399  0.5616\n",
      " 0.4798  0.4783  0.1805  0.8898\n",
      "[torch.FloatTensor of size 3x4]\n",
      "\n",
      "\n",
      " 0.8031  0.6118  0.0423  0.0696\n",
      " 0.0763  0.6341  0.9399  0.5616\n",
      " 0.4798  0.4783  0.1805  0.8898\n",
      "[torch.FloatTensor of size 3x4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "z = torch.Tensor(3, 4)\n",
    "z.copy_(x) #copy x to z\n",
    "print x\n",
    "print z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 2.4094  1.8353  0.1268  0.2087\n",
      " 0.2290  1.9023  2.8198  1.6848\n",
      " 1.4393  1.4348  0.5415  2.6693\n",
      "[torch.FloatTensor of size 3x4]\n",
      "\n",
      "\n",
      " 0.8031  0.6118  0.0423  0.0696\n",
      " 0.0763  0.6341  0.9399  0.5616\n",
      " 0.4798  0.4783  0.1805  0.8898\n",
      "[torch.FloatTensor of size 3x4]\n",
      "\n",
      "\n",
      " 2.4094  1.8353  0.1268  0.2087\n",
      " 0.2290  1.9023  2.8198  1.6848\n",
      " 1.4393  1.4348  0.5415  2.6693\n",
      "[torch.FloatTensor of size 3x4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print z.add_(x)\n",
    "print x\n",
    "print z #note that z is replaced with the sum, but x stays the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1.6063  1.2235  0.0845  0.1391\n",
      " 0.1527  1.2682  1.8798  1.1232\n",
      " 0.9595  0.9565  0.3610  1.7796\n",
      "[torch.FloatTensor of size 3x4]\n",
      "\n",
      "\n",
      " 0.8031  0.6118  0.0423  0.0696\n",
      " 0.0763  0.6341  0.9399  0.5616\n",
      " 0.4798  0.4783  0.1805  0.8898\n",
      "[torch.FloatTensor of size 3x4]\n",
      "\n",
      "\n",
      " 0.8031  0.6118  0.0423  0.0696\n",
      " 0.0763  0.6341  0.9399  0.5616\n",
      " 0.4798  0.4783  0.1805  0.8898\n",
      "[torch.FloatTensor of size 3x4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## the add() operation is not changing either x or zz\n",
    "zz = x\n",
    "print zz.add(x)\n",
    "print x\n",
    "print zz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1.6063  1.2235  0.0845  0.1391\n",
      " 0.1527  1.2682  1.8798  1.1232\n",
      " 0.9595  0.9565  0.3610  1.7796\n",
      "[torch.FloatTensor of size 3x4]\n",
      "\n",
      "\n",
      " 1.6063  1.2235  0.0845  0.1391\n",
      " 0.1527  1.2682  1.8798  1.1232\n",
      " 0.9595  0.9565  0.3610  1.7796\n",
      "[torch.FloatTensor of size 3x4]\n",
      "\n",
      "\n",
      " 1.6063  1.2235  0.0845  0.1391\n",
      " 0.1527  1.2682  1.8798  1.1232\n",
      " 0.9595  0.9565  0.3610  1.7796\n",
      "[torch.FloatTensor of size 3x4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### note that both x and zzz have been changed\n",
    "\n",
    "zzz = x\n",
    "print zzz.add_(x)\n",
    "print x\n",
    "print zzz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 跟Numpy的联接\n",
    "pytorch跟numpy的衔接还表现在二者之间的轻松转换，Pytorch中tensor支持所有numpy中的索引操作，并包含几乎所有基础操作函数。\n",
    "\n",
    "As a replacement for Numpy, Pytorch is nicely connected to Numpy. It supports all numpy-style indexing, and its tensor datatype can be simply converted to numpy ndarrays. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[torch.FloatTensor of size 3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a= torch.ones(3)\n",
    "print a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'> [ 1.  1.  1.]\n",
      "<class 'torch.FloatTensor'> \n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "<class 'torch.FloatTensor'> \n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[torch.FloatTensor of size 3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "b = a.numpy()\n",
    "c = torch.from_numpy(b)\n",
    "print type(b), b  #b is numpy array converted from a\n",
    "print type(a), a  #a is torch tensor\n",
    "print type(c), c  #c is torch tensor converted from b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意上例中a和b共享内存，当对a进行in place操作时，不仅a的值发生了变化，b也跟着变了。\n",
    "\n",
    "Converting a torch Tensor to a numpy array and vice versa is a breeze. The torch Tensor and numpy array will share their underlying memory locations, and changing one will change the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 3\n",
      " 3\n",
      " 3\n",
      "[torch.FloatTensor of size 3]\n",
      " [ 3.  3.  3.]\n"
     ]
    }
   ],
   "source": [
    "a.add_(2)\n",
    "print a, b  #Note that both a and b are changed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Torch tensors can be moved to GPU using ``.cuda`` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    a = a.cuda()\n",
    "    b = b.cuda()\n",
    "    c = a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = torch.randn(3, 4, 2)\n",
    "b = torch.randn(3, 2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected argument self to have 1 dimension(s), but has 3 at /pytorch/torch/csrc/generic/TensorMethods.cpp:23020",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-9474ab37f7e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected argument self to have 1 dimension(s), but has 3 at /pytorch/torch/csrc/generic/TensorMethods.cpp:23020"
     ]
    }
   ],
   "source": [
    "c = a.dot(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "matrices expected, got 3D, 3D tensors at /pytorch/torch/lib/TH/generic/THTensorMath.c:1288",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-a98d0c01ed5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: matrices expected, got 3D, 3D tensors at /pytorch/torch/lib/TH/generic/THTensorMath.c:1288"
     ]
    }
   ],
   "source": [
    "c = a.mm(b)\n",
    "print c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "c = a.matmul(b)\n",
    "print c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.17914605141\n",
      "1.17914605141\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 2: dimension 1 out of range of 1D tensor at /pytorch/torch/lib/TH/generic/THTensor.c:24",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-16b383b9f325>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid argument 2: dimension 1 out of range of 1D tensor at /pytorch/torch/lib/TH/generic/THTensor.c:24"
     ]
    }
   ],
   "source": [
    "a, b = torch.randn(4, ), torch.randn(4, )\n",
    "print a.dot(b)\n",
    "print a.matmul(b)\n",
    "print a.mm(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
