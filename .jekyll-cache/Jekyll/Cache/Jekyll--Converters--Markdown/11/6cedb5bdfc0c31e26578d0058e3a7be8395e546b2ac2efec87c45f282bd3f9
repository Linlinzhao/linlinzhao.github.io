I"¢<p><em>In an earlier <a href="https://linlinzhao.com/probability/2015/07/12/Bayesian-basics1-way-of-reasoning.html">post</a>, we get to know the concept of Bayesian reasoning. In this post we show Bayesian way of inferring basic statistics and briefly compare the Maximum a Posteriori to Maximum likelihood.</em></p>

<p>As a simple example of Bayesian inference in action, we estimate the expectation \(\mu\) of univariate Gaussian with known variance \(\sigma^2\). 
Assuming \(N\) observations as \(X=(x_1,\cdots, x_N)\), maximum likelihood estimate gives \(\mu=\sum_kx_k/N=\bar X\), of which the calculation details are neglected. Now we focus on Bayesian estimate.</p>

:ET